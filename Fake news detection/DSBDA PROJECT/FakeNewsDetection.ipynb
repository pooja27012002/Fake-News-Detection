{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***Fake News Detection***\n",
        "\n",
        "*   **Group ID : 12**\n",
        "\n",
        "    Guide : ***Prof. Yogita Fatangare***\n",
        "\n",
        "    Group Members:\n",
        "\n",
        "    1. ***Shraddha Bhoite (35009)***\n",
        "\n",
        "    2. ***Pooja Jadhav (35033)***\n",
        "\n",
        "    3. ***Prajakta Kank (35040)***\n",
        "\n",
        "    4. ***Sanket Kurle (35051)***\n",
        "\n",
        "    PES's MCOE, BE - Information Technology\n",
        "    2021-22 \n",
        "\n"
      ],
      "metadata": {
        "id": "71E-9pLP20OZ"
      },
      "id": "71E-9pLP20OZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Importing Libraries*"
      ],
      "metadata": {
        "id": "myuZhxow3hFj"
      },
      "id": "myuZhxow3hFj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "380fc42a",
      "metadata": {
        "id": "380fc42a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The Dataset*"
      ],
      "metadata": {
        "id": "ma69su-O4L-M"
      },
      "id": "ma69su-O4L-M"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19fe9321",
      "metadata": {
        "id": "19fe9321",
        "outputId": "a64bd08f-0a96-462e-f799-bd2e7faea912"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data shape =  (7613, 5)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train = pd.read_csv(\"traindata.csv\")\n",
        "print(\"Data shape = \",data_train.shape)\n",
        "data_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Dropping the not required columns*"
      ],
      "metadata": {
        "id": "OI3DW_Sm4c2t"
      },
      "id": "OI3DW_Sm4c2t"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43fadeb6",
      "metadata": {
        "id": "43fadeb6",
        "outputId": "ad7c6ef6-bf35-495c-f42e-06b5a11718de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "location and keyword columns droped successfully\n",
            "id column droped successfully\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Index(['text', 'target'], dtype='object')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train = data_train.drop(['location','keyword'], axis=1)\n",
        "print(\"location and keyword columns droped successfully\")\n",
        "\n",
        "data_train = data_train.drop('id', axis=1)\n",
        "print(\"id column droped successfully\")\n",
        "data_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce7bc66f",
      "metadata": {
        "id": "ce7bc66f",
        "outputId": "dfa959aa-761e-4ad4-bfe7-32e672d95df8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7608</th>\n",
              "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7609</th>\n",
              "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7610</th>\n",
              "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7611</th>\n",
              "      <td>Police investigating after an e-bike collided ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7612</th>\n",
              "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  target\n",
              "0     Our Deeds are the Reason of this #earthquake M...       1\n",
              "1                Forest fire near La Ronge Sask. Canada       1\n",
              "2     All residents asked to 'shelter in place' are ...       1\n",
              "3     13,000 people receive #wildfires evacuation or...       1\n",
              "4     Just got sent this photo from Ruby #Alaska as ...       1\n",
              "...                                                 ...     ...\n",
              "7608  Two giant cranes holding a bridge collapse int...       1\n",
              "7609  @aria_ahrary @TheTawniest The out of control w...       1\n",
              "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1\n",
              "7611  Police investigating after an e-bike collided ...       1\n",
              "7612  The Latest: More Homes Razed by Northern Calif...       1\n",
              "\n",
              "[7613 rows x 2 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Create corpus a feature of NLP*"
      ],
      "metadata": {
        "id": "ooGWQRix4kyR"
      },
      "id": "ooGWQRix4kyR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8282ff9",
      "metadata": {
        "id": "e8282ff9",
        "outputId": "4b4caaae-1d67-4371-e86d-30e8b0f51aa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Corpus created successfully\n"
          ]
        }
      ],
      "source": [
        "corpus  = []\n",
        "pstem = PorterStemmer()\n",
        "for i in range(data_train['text'].shape[0]):\n",
        "    #Remove unwanted words\n",
        "    token = re.sub(\"[^a-zA-Z]\", ' ', data_train['text'][i])\n",
        "    #Transform words to lowercase\n",
        "    token = token.lower()\n",
        "    token = token.split()\n",
        "    #Remove stopwords then Stemming it\n",
        "    token = [pstem.stem(word) for word in token if not word in set(stopwords.words('english'))]\n",
        "    token = ' '.join(token)\n",
        "    #Append cleaned token to corpus\n",
        "    corpus.append(token)\n",
        "    \n",
        "print(\"Corpus created successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Create dictionary*"
      ],
      "metadata": {
        "id": "100jiAFR5Ot4"
      },
      "id": "100jiAFR5Ot4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7848e4c2",
      "metadata": {
        "id": "7848e4c2",
        "outputId": "6989547f-f937-4c9d-aaa3-2543a0bf4b07"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word Frequent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>co</th>\n",
              "      <td>4746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>http</th>\n",
              "      <td>4721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>like</th>\n",
              "      <td>411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fire</th>\n",
              "      <td>363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amp</th>\n",
              "      <td>344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>get</th>\n",
              "      <td>311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bomb</th>\n",
              "      <td>239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>new</th>\n",
              "      <td>228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>via</th>\n",
              "      <td>220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u</th>\n",
              "      <td>216</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Word Frequent\n",
              "co             4746\n",
              "http           4721\n",
              "like            411\n",
              "fire            363\n",
              "amp             344\n",
              "get             311\n",
              "bomb            239\n",
              "new             228\n",
              "via             220\n",
              "u               216"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uniqueWordFrequents = {}\n",
        "for token in corpus:\n",
        "    for word in token.split():\n",
        "        if(word in uniqueWordFrequents.keys()):\n",
        "            uniqueWordFrequents[word] += 1\n",
        "        else:\n",
        "            uniqueWordFrequents[word] = 1\n",
        "            \n",
        "#Convert dictionary to dataFrame\n",
        "uniqueWordFrequents = pd.DataFrame.from_dict(uniqueWordFrequents,orient='index',columns=['Word Frequent'])\n",
        "uniqueWordFrequents.sort_values(by=['Word Frequent'], inplace=True, ascending=False)\n",
        "uniqueWordFrequents.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ce23b74",
      "metadata": {
        "id": "1ce23b74",
        "outputId": "730aedfe-0ac7-4104-8870-e4829e4548d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4746, 4721,  411,  363,  344,  311,  239,  228,  220,  216,  213,\n",
              "        210,  209,  201,  183,  181,  180,  178,  175,  169,  166,  164,\n",
              "        162,  156,  155,  153,  151,  145,  144,  143,  137,  133,  132,\n",
              "        131,  130,  129,  128,  125,  124,  123,  122,  121,  120,  119,\n",
              "        118,  117,  116,  114,  111,  110,  109,  108,  106,  105,  104,\n",
              "        103,  102,  101,  100,   99,   98,   97,   96,   95,   94,   93,\n",
              "         91,   90,   89,   88,   87,   86,   84,   83,   82,   79,   78,\n",
              "         77,   76,   75,   74,   73,   72,   71,   70,   69,   68,   67,\n",
              "         66,   65,   64,   63,   62,   61,   60,   59,   58,   57,   56,\n",
              "         55,   54,   53,   52,   51,   50,   49,   48,   47,   46,   45,\n",
              "         44,   43,   42,   41,   40,   39,   38,   37,   36,   35,   34,\n",
              "         33,   32,   31,   30,   29,   28,   27,   26,   25,   24,   23,\n",
              "         22,   21,   20,   19,   18,   17,   16,   15,   14,   13,   12,\n",
              "         11,   10,    9,    8,    7,    6,    5,    4,    3,    2,    1],\n",
              "      dtype=int64)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uniqueWordFrequents['Word Frequent'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc92885e",
      "metadata": {
        "id": "bc92885e",
        "outputId": "859c27da-c876-4a62-f161-8629048a7ede"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(787, 1)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word Frequent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>co</th>\n",
              "      <td>4746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>http</th>\n",
              "      <td>4721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>like</th>\n",
              "      <td>411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fire</th>\n",
              "      <td>363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amp</th>\n",
              "      <td>344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cnn</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gem</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>captur</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>arriv</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carri</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>787 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Word Frequent\n",
              "co               4746\n",
              "http             4721\n",
              "like              411\n",
              "fire              363\n",
              "amp               344\n",
              "...               ...\n",
              "cnn                20\n",
              "gem                20\n",
              "captur             20\n",
              "arriv              20\n",
              "carri              20\n",
              "\n",
              "[787 rows x 1 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uniqueWordFrequents = uniqueWordFrequents[uniqueWordFrequents['Word Frequent'] >= 20]\n",
        "print(uniqueWordFrequents.shape)\n",
        "uniqueWordFrequents"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Bag of word and CountVectorizer*"
      ],
      "metadata": {
        "id": "mPJGdb-S5d6h"
      },
      "id": "mPJGdb-S5d6h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bcf1c37",
      "metadata": {
        "id": "8bcf1c37"
      },
      "outputs": [],
      "source": [
        "counVec = CountVectorizer(max_features = uniqueWordFrequents.shape[0])\n",
        "bagOfWords = counVec.fit_transform(corpus).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccfb04f7",
      "metadata": {
        "id": "ccfb04f7",
        "outputId": "46bb80d9-bc78-410c-ad0e-22854e9dc460"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape =  (7613, 787)\n",
            "y shape =  (7613,)\n",
            "data splitting successfully\n"
          ]
        }
      ],
      "source": [
        "X = bagOfWords\n",
        "y = data_train['target']\n",
        "print(\"X shape = \",X.shape)\n",
        "print(\"y shape = \",y.shape)\n",
        "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.20, random_state=55, shuffle =True)\n",
        "print('data splitting successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Multinomial DB*"
      ],
      "metadata": {
        "id": "RVGWCZiD5pPJ"
      },
      "id": "RVGWCZiD5pPJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a965ddd",
      "metadata": {
        "id": "0a965ddd",
        "outputId": "ccc4cd7f-29c8-48f8-f88e-a423635f8b41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "multinomialNB model run successfully\n"
          ]
        }
      ],
      "source": [
        "multinomialNBModel = MultinomialNB(alpha=0.1)\n",
        "multinomialNBModel.fit(X_train,y_train)\n",
        "print(\"multinomialNB model run successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Evaluation Details*"
      ],
      "metadata": {
        "id": "yaiON64A5yIa"
      },
      "id": "yaiON64A5yIa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d5f184",
      "metadata": {
        "id": "e6d5f184",
        "outputId": "621d9405-2d2e-4fd6-dc7e-c67bb22e7427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultinomialNB  Train Score is   :  0.8022988505747126\n",
            "MultinomialNB  Test Score is    :  0.7734734077478661\n",
            "MultinomialNB  F1 Score is      :  0.7165160230073953\n",
            "----------------------\n"
          ]
        }
      ],
      "source": [
        "models = [multinomialNBModel]\n",
        "for model in models:\n",
        "    print(type(model).__name__,' Train Score is   : ' ,model.score(X_train, y_train))\n",
        "    print(type(model).__name__,' Test Score is    : ' ,model.score(X_test, y_test))\n",
        "    \n",
        "    y_pred = model.predict(X_test)\n",
        "    print(type(model).__name__,' F1 Score is      : ' ,f1_score(y_test,y_pred))\n",
        "    print('----------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c03dce5",
      "metadata": {
        "id": "5c03dce5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "288e3fa0",
      "metadata": {
        "id": "288e3fa0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "FakeNewsDetection.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}